from functools import total_ordering
import requests
from peewee import *
from datetime import datetime
import html
import time
import random
import math
import re
import os
import locale
from pathlib import Path
import json
# å¯¼å…¥dotenvåº“ä»¥æ”¯æŒä».envæ–‡ä»¶è¯»å–ç¯å¢ƒå˜é‡
try:
    from dotenv import load_dotenv
    load_dotenv()  # åŠ è½½.envæ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡
    print("DEBUG: å·²åŠ è½½dotenvåº“å¹¶ä».envæ–‡ä»¶è¯»å–ç¯å¢ƒå˜é‡")
except ImportError:
    print("DEBUG: æœªå®‰è£…dotenvåº“ï¼Œè·³è¿‡ä».envæ–‡ä»¶è¯»å–ç¯å¢ƒå˜é‡")

# ç¡®å®šé¡¹ç›®æ ¹ç›®å½•
def get_project_root():
    """
    è·å–é¡¹ç›®æ ¹ç›®å½•çš„ç»å¯¹è·¯å¾„ï¼Œå¤„ç†åµŒå¥—ç›®å½•æƒ…å†µ
    è§£å†³GitHub Actionsç¯å¢ƒä¸­çš„ç›®å½•åµŒå¥—é—®é¢˜
    """
    # è·å–å½“å‰æ–‡ä»¶æ‰€åœ¨ç›®å½•ï¼ˆåŒ…å«main.pyçš„ç›®å½•ï¼‰
    current_file_path = os.path.abspath(__file__)
    current_dir = os.path.dirname(current_file_path)
    print(f"DEBUG: å½“å‰æ–‡ä»¶è·¯å¾„: {current_file_path}")
    print(f"DEBUG: å½“å‰ç›®å½•: {current_dir}")
    
    # æƒ…å†µ1: æ£€æŸ¥å½“å‰ç›®å½•æ˜¯å¦å·²ç»åŒ…å«æ‰€æœ‰å¿…è¦æ–‡ä»¶/ç›®å½•
    if os.path.exists(os.path.join(current_dir, 'main.py')) and \
       os.path.exists(os.path.join(current_dir, 'docs')) and \
       os.path.exists(os.path.join(current_dir, 'db')):
        print(f"DEBUG: å½“å‰ç›®å½•å·²åŒ…å«æ‰€æœ‰å¿…è¦æ–‡ä»¶/ç›®å½•")
        return current_dir
    
    # æƒ…å†µ2: æ£€æŸ¥GitHub Actionså…¸å‹åµŒå¥—ç»“æ„
    # åœ¨GitHub Actionsä¸­ï¼Œä»£ç é€šå¸¸åœ¨ /home/runner/work/repo_name/repo_name ä¸­
    if 'runner' in current_dir and 'work' in current_dir:
        # æŸ¥æ‰¾æœ€åä¸€ä¸ªé¡¹ç›®ç›®å½•å
        parts = current_dir.split(os.path.sep)
        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨åµŒå¥—çš„é¡¹ç›®ç›®å½•
        for i, part in enumerate(parts):
            if part and i < len(parts) - 1 and parts[i] == parts[i+1]:
                # æ‰¾åˆ°åµŒå¥—ç›®å½•ï¼Œè¿”å›å®Œæ•´è·¯å¾„
                nested_path = os.path.sep.join(parts[:i+2])
                if os.path.exists(os.path.join(nested_path, 'main.py')):
                    print(f"DEBUG: æ£€æµ‹åˆ°GitHub ActionsåµŒå¥—ç›®å½•ç»“æ„: {nested_path}")
                    return nested_path
    
    # æƒ…å†µ3: å°è¯•å‘ä¸‹æŸ¥æ‰¾ï¼ˆé’ˆå¯¹GitHub Actionsç¯å¢ƒï¼Œå¯èƒ½å½“å‰åœ¨workç›®å½•è€Œä¸æ˜¯å®é™…ä»£ç ç›®å½•ï¼‰
    # æ£€æŸ¥å½“å‰ç›®å½•ä¸‹æ˜¯å¦æœ‰åä¸ºgithub_cve_monitorçš„å­ç›®å½•
    possible_nested_dir = os.path.join(current_dir, 'github_cve_monitor')
    if os.path.exists(possible_nested_dir) and \
       os.path.exists(os.path.join(possible_nested_dir, 'main.py')) and \
       os.path.exists(os.path.join(possible_nested_dir, 'docs')) and \
       os.path.exists(os.path.join(possible_nested_dir, 'db')):
        print(f"DEBUG: æ£€æµ‹åˆ°å‘ä¸‹åµŒå¥—çš„é¡¹ç›®ç›®å½•: {possible_nested_dir}")
        return possible_nested_dir
    
    # æƒ…å†µ4: é€çº§å‘ä¸ŠæŸ¥æ‰¾
    test_dir = current_dir
    max_depth = 5  # è®¾ç½®æœ€å¤§æŸ¥æ‰¾æ·±åº¦
    
    for depth in range(max_depth):
        # å‘ä¸Šä¸€çº§ç›®å½•
        parent_dir = os.path.dirname(test_dir)
        if parent_dir == test_dir:  # åˆ°è¾¾æ–‡ä»¶ç³»ç»Ÿæ ¹ç›®å½•
            print(f"DEBUG: åˆ°è¾¾æ–‡ä»¶ç³»ç»Ÿæ ¹ç›®å½•")
            break
        
        print(f"DEBUG: å‘ä¸ŠæŸ¥æ‰¾å±‚çº§ {depth+1}: {parent_dir}")
        
        # æ£€æŸ¥çˆ¶ç›®å½•æ˜¯å¦åŒ…å«æ‰€æœ‰å¿…è¦æ–‡ä»¶/ç›®å½•
        if os.path.exists(os.path.join(parent_dir, 'main.py')) and \
           os.path.exists(os.path.join(parent_dir, 'docs')) and \
           os.path.exists(os.path.join(parent_dir, 'db')):
            print(f"DEBUG: åœ¨çˆ¶ç›®å½•æ‰¾åˆ°é¡¹ç›®æ ¹ç›®å½•: {parent_dir}")
            return parent_dir
        
        test_dir = parent_dir
    
    # å¦‚æœæ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥ï¼Œè¿”å›å½“å‰ç›®å½•ä½œä¸ºæœ€åæ‰‹æ®µ
    print(f"DEBUG: æ— æ³•ç¡®å®šé¡¹ç›®æ ¹ç›®å½•ï¼Œè¿”å›å½“å‰ç›®å½•ä½œä¸ºé»˜è®¤å€¼")
    return current_dir

# è·å–é¡¹ç›®æ ¹ç›®å½•
PROJECT_ROOT = get_project_root()
print(f"DEBUG: é¡¹ç›®æ ¹ç›®å½•: {PROJECT_ROOT}")


# è®¾ç½®ä¸­æ–‡ç¯å¢ƒ
try:
    locale.setlocale(locale.LC_ALL, 'zh_CN.UTF-8')
except:
    try:
        locale.setlocale(locale.LC_ALL, 'Chinese_China.936')
    except:
        pass  # å¦‚æœè®¾ç½®å¤±è´¥ï¼Œä½¿ç”¨ç³»ç»Ÿé»˜è®¤

db = SqliteDatabase(os.path.join(PROJECT_ROOT, "db/cve.sqlite"))

class CVE_DB(Model):
    id = IntegerField()
    full_name = CharField(max_length=1024)
    description = CharField(max_length=4098)
    url = CharField(max_length=1024)
    created_at = CharField(max_length=128)
    cve = CharField(max_length=64)

    class Meta:
        database = db

db.connect()
db.create_tables([CVE_DB])

def init_file():
    newline = "# Github CVE Monitor\n\n> Automatic monitor github cve using Github Actions \n\n Last generated : {}\n\n| CVE | ç›¸å…³ä»“åº“ï¼ˆpoc/expï¼‰ | æè¿° | æ—¥æœŸ |\n|---|---|---|---|\n".format(datetime.now())
    with open(os.path.join(PROJECT_ROOT, 'docs/README.md'),'w', encoding='utf-8') as f:
        f.write(newline) 
    f.close()

def write_file(new_contents, overwrite=False):
    """ä¼˜åŒ–çš„æ–‡ä»¶å†™å…¥å‡½æ•°ï¼Œå‡å°‘I/Oæ“ä½œ"""
    mode = 'w' if overwrite else 'a'
    # ä½¿ç”¨withè¯­å¥è‡ªåŠ¨å¤„ç†æ–‡ä»¶å…³é—­ï¼Œé¿å…æ˜¾å¼è°ƒç”¨f.close()
    with open(os.path.join(PROJECT_ROOT, 'docs/README.md'), mode, encoding='utf-8') as f:
        f.write(new_contents)

def init_daily_file(date_str):
    """åˆå§‹åŒ–æ¯æ—¥æŠ¥å‘Šæ–‡ä»¶"""
    # åˆ›å»ºæ—¥æœŸç›®å½•
    today = datetime.now()
    year = today.year
    week_number = today.strftime("%W")
    month = today.strftime("%m")
    day = today.strftime("%d")
    
    # åˆ›å»ºç›®å½•ç»“æ„ /reports/weekly/YYYY-W-mm-dd
    dir_path = os.path.join(PROJECT_ROOT, f"docs/reports/weekly/{year}-W{week_number}-{month}-{day}")
    Path(dir_path).mkdir(parents=True, exist_ok=True)
    
    # åˆ›å»ºæ¯æ—¥æŠ¥å‘Šæ–‡ä»¶
    file_path = os.path.join(dir_path, f"daily_{date_str}.md")
    newline = f"""# æ¯æ—¥ æƒ…æŠ¥é€Ÿé€’ æŠ¥å‘Š ({date_str})

> Automatic monitor Github CVE using Github Actions 

## æŠ¥å‘Šä¿¡æ¯
- **ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- **æ•°æ®æ¥æº**: GitHub CVE æ•°æ®åº“

## ä»Šæ—¥ æƒ…æŠ¥é€Ÿé€’

| CVE | ç›¸å…³ä»“åº“ï¼ˆpoc/expï¼‰ | æè¿° | æ—¥æœŸ |
|:---|:---|:---|:---|
"""
    
    with open(file_path, 'w', encoding='utf-8') as f:
        f.write(newline)
    
    return file_path

def write_daily_file(file_path, new_contents):
    """ä¼˜åŒ–çš„æ¯æ—¥æŠ¥å‘Šå†™å…¥å‡½æ•°ï¼Œå‡å°‘I/Oæ“ä½œ"""
    # ç¡®ä¿æ–‡ä»¶è·¯å¾„æ­£ç¡®
    if not os.path.isabs(file_path):
        file_path = os.path.join(PROJECT_ROOT, file_path)
    # ä½¿ç”¨withè¯­å¥è‡ªåŠ¨å¤„ç†æ–‡ä»¶å…³é—­
    with open(file_path, 'a', encoding='utf-8') as f:
        f.write(new_contents)

def update_daily_index():
    """æ›´æ–°æ¯æ—¥ æƒ…æŠ¥é€Ÿé€’ æŠ¥å‘Šç´¢å¼•æ–‡ä»¶"""
    data_dir = Path(os.path.join(PROJECT_ROOT, "docs/reports/weekly"))
    if not data_dir.exists():
        return
    
    # åˆ›å»ºç´¢å¼•æ–‡ä»¶
    index_path = data_dir / "index.md"
    with open(index_path, 'w', encoding='utf-8') as f:
        f.write("# æ¯æ—¥ æƒ…æŠ¥é€Ÿé€’ æŠ¥å‘Šç´¢å¼•\n\n")
        f.write("> Automatic monitor Github CVE using Github Actions\n\n")
        f.write("## å¯ç”¨æŠ¥å‘Š\n\n")
    
    # éå†æ‰€æœ‰æ—¥æœŸç›®å½•
    date_dirs = sorted([d for d in data_dir.glob("*-W*-*-*")], reverse=True)
    
    for date_dir in date_dirs:
        dir_name = date_dir.name
        with open(index_path, 'a', encoding='utf-8') as f:
            f.write(f"### {dir_name}\n\n")
        
        # éå†è¯¥ç›®å½•ä¸‹çš„æ‰€æœ‰dailyæŠ¥å‘Š
        daily_files = sorted([f for f in date_dir.glob("daily_*.md")], reverse=True)
        
        for daily_file in daily_files:
            file_name = daily_file.name
            relative_path = f"data/{date_dir.name}/{file_name}"
            date_str = file_name.replace("daily_", "").replace(".md", "")
            
            # æ ¼å¼åŒ–æ—¥æœŸæ˜¾ç¤º
            try:
                formatted_date = f"{date_str[:4]}-{date_str[4:6]}-{date_str[6:]}"
            except:
                formatted_date = date_str
            
            with open(index_path, 'a', encoding='utf-8') as f:
                f.write(f"- [{formatted_date} æ¯æ—¥æŠ¥å‘Š]({relative_path})\n")
        
        with open(index_path, 'a', encoding='utf-8') as f:
            f.write("\n")
    
    # æ›´æ–°ä¾§è¾¹æ ï¼Œæ·»åŠ æ¯æ—¥æŠ¥å‘Šé“¾æ¥
    update_sidebar()

def update_sidebar():
    """æ›´æ–°ä¾§è¾¹æ ï¼Œæ·»åŠ æ¯æ—¥æŠ¥å‘Šé“¾æ¥"""
    sidebar_path = Path(os.path.join(PROJECT_ROOT, "docs/_sidebar.md"))
    if not sidebar_path.exists():
        return
    
    # è¯»å–ç°æœ‰ä¾§è¾¹æ å†…å®¹
    with open(sidebar_path, 'r', encoding='utf-8') as f:
        lines = f.readlines()
    
    # æ£€æŸ¥æ˜¯å¦å·²æœ‰æ¯æ—¥æŠ¥å‘Šé“¾æ¥
    daily_report_exists = False
    for line in lines:
        if "æ¯æ—¥æŠ¥å‘Š" in line:
            daily_report_exists = True
            break
    
    # å¦‚æœæ²¡æœ‰æ¯æ—¥æŠ¥å‘Šé“¾æ¥ï¼Œæ·»åŠ åˆ°ä¾§è¾¹æ 
    if not daily_report_exists:
        # æ‰¾åˆ°åˆé€‚çš„ä½ç½®æ’å…¥é“¾æ¥
        new_lines = []
        for line in lines:
            new_lines.append(line)
            # åœ¨ä¸»é¡µé“¾æ¥åæ·»åŠ æ¯æ—¥æŠ¥å‘Šé“¾æ¥
            if "- [ä¸»é¡µ](README.md)" in line or "- [Home](README.md)" in line:
                new_lines.append("- [æ¯æ—¥æŠ¥å‘Š](/data/index.md)\n")
        
        # å†™å›æ–‡ä»¶
        with open(sidebar_path, 'w', encoding='utf-8') as f:
            f.writelines(new_lines)

def load_config():
    """ä»é…ç½®æ–‡ä»¶åŠ è½½é…ç½®ä¿¡æ¯"""
    config_paths = [
        os.path.join(PROJECT_ROOT, "docs/config/config.json"),
        os.path.join(PROJECT_ROOT, "docs/data/config.json"),
        os.path.join(PROJECT_ROOT, "docs/config.json"),
        os.path.join(PROJECT_ROOT, "config.json")
    ]
    
    for config_path in config_paths:
        if os.path.exists(config_path):
            try:
                with open(config_path, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                    return config
            except Exception as e:
                print(f"è­¦å‘Š: æ— æ³•è¯»å–é…ç½®æ–‡ä»¶ {config_path}: {e}")
    
    return {}

def get_github_token():
    """è·å–GitHub Tokenï¼Œä¼˜å…ˆçº§ï¼šç¯å¢ƒå˜é‡(.envæˆ–ç³»ç»Ÿç¯å¢ƒå˜é‡) > é…ç½®æ–‡ä»¶"""
    # é¦–å…ˆæ£€æŸ¥ç¯å¢ƒå˜é‡ï¼ˆä¼šè‡ªåŠ¨åŒ…æ‹¬ä».envæ–‡ä»¶åŠ è½½çš„å˜é‡ï¼‰
    github_token = os.environ.get('GITHUB_TOKEN')
    if github_token:
        print(f"DEBUG: ä»ç¯å¢ƒå˜é‡è·å–åˆ°GITHUB_TOKEN")
        print(f"DEBUG: Tokené•¿åº¦: {len(github_token)}")
        # ä¸è¦æ‰“å°å®Œæ•´çš„tokenï¼Œä½†å¯ä»¥æ‰“å°å‰å‡ ä¸ªå­—ç¬¦æ¥ç¡®è®¤
        if len(github_token) > 5:
            print(f"DEBUG: Tokenå‰ç¼€: {github_token[:5]}...")
        return github_token
    
    # ç„¶åæ£€æŸ¥é…ç½®æ–‡ä»¶
    config = load_config()
    github_token = config.get('github_token')
    if github_token and github_token != "your_token_here":
        print(f"DEBUG: ä»é…ç½®æ–‡ä»¶è·å–åˆ°github_token")
        print(f"DEBUG: Tokené•¿åº¦: {len(github_token)}")
        if len(github_token) > 5:
            print(f"DEBUG: Tokenå‰ç¼€: {github_token[:5]}...")
        return github_token
    
    print("DEBUG: æœªæ‰¾åˆ°æœ‰æ•ˆçš„GitHub Token")
    print("DEBUG: æ‚¨å¯ä»¥åœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»º.envæ–‡ä»¶ï¼Œå¹¶æ·»åŠ GITHUB_TOKEN=your_token_here")
    return None

def get_info(year):
    """
    è·å–æŒ‡å®šå¹´ä»½çš„CVEç›¸å…³GitHubä»“åº“ä¿¡æ¯
    ä¼˜åŒ–ç‰ˆæœ¬ - å‡å°‘APIè°ƒç”¨ç­‰å¾…æ—¶é—´å’Œä¸å¿…è¦çš„å¤„ç†
    """
    try:
        all_items = []
        page = 1
        # å¢åŠ æ— tokenæ—¶çš„æ‰¹é‡å¤§å°
        per_page = 100 if os.environ.get("GITHUB_TOKEN") else 50
        github_token = get_github_token()
        headers = {
            'User-Agent': 'CVE-Monitor-App/1.0 (+https://github.com/adminlove520/github_cve_monitor)', 
            'Accept': 'application/vnd.github.v3+json'
        }

        if github_token:
            headers['Authorization'] = f'token {github_token}'
        
        # è¿›ä¸€æ­¥å‡å°‘æœ€å¤§é¡µæ•°
        max_pages = 5
        max_retries = 1  # å‡å°‘é‡è¯•æ¬¡æ•°
        
        # ä½¿ç”¨æ›´é«˜æ•ˆçš„æŸ¥è¯¢è¯­æ³•
        query = f"CVE-{year} created:{year}-01-01..{year}-12-31 sort:updated-desc"
        
        while page <= max_pages:
            api = f"https://api.github.com/search/repositories?q={query}&page={page}&per_page={per_page}"
            
            # ç®€å•å»¶è¿Ÿ - æœ€å°åŒ–ç­‰å¾…æ—¶é—´
            if page > 1:
                wait_time = 0.5 if github_token else 1
                time.sleep(wait_time)
            
            # ä½¿ç”¨ç®€åŒ–çš„è¯·æ±‚å¤„ç†
            retry_count = 0
            while retry_count < max_retries:
                try:
                    response = requests.get(api, headers=headers, timeout=10)
                    
                    # å¤„ç†å“åº”
                    if response.status_code == 200:
                        try:
                            data = response.json()
                            if 'items' in data:
                                items = data['items']
                                if items:
                                    all_items.extend(items)
                                    
                                    # æ£€æŸ¥æ˜¯å¦æœ‰ä¸‹ä¸€é¡µ
                                    if len(items) < per_page:
                                        return all_items
                                    
                                    # ç»§ç»­ä¸‹ä¸€é¡µ
                                    page += 1
                                    break
                                else:
                                    return all_items
                        except json.JSONDecodeError:
                            retry_count += 1
                    
                    # å¿«é€Ÿå¤±è´¥å¤„ç†å…¶ä»–çŠ¶æ€ç 
                    else:
                        break
                
                except Exception:
                    retry_count += 1
            
            # å¿«é€Ÿè·³è¿‡å¤±è´¥çš„é¡µé¢
            if retry_count >= max_retries or response.status_code != 200:
                page += 1
        
        # å»é‡å¤„ç†
        seen = set()
        unique_items = []
        for item in all_items:
            if item['id'] not in seen:
                seen.add(item['id'])
                unique_items.append(item)
                
        return unique_items
    
    except Exception as e:
        return []  # é™é»˜å¤±è´¥ï¼Œè¿”å›ç©ºåˆ—è¡¨


def db_match(items):
    """ä¼˜åŒ–çš„æ•°æ®åº“åŒ¹é…å‡½æ•°ï¼Œä½¿ç”¨æ‰¹é‡æ“ä½œæé«˜æ€§èƒ½"""
    if not items:
        return []
        
    r_list = []
    regex = r"[Cc][Vv][Ee][-_]\d{4}[-_]\d{4,7}"
    
    # æ‰¹é‡è·å–ç°æœ‰IDä»¥é¿å…é‡å¤æ’å…¥
    all_ids = [item["id"] for item in items]
    existing_ids = set(
        row.id for row in CVE_DB.select(CVE_DB.id).where(CVE_DB.id.in_(all_ids))
    )
    
    # å‡†å¤‡æ‰¹é‡æ’å…¥çš„æ•°æ®
    to_insert = []
    
    for item in items:
        id = item["id"]
        # è·³è¿‡å·²å­˜åœ¨çš„è®°å½•
        if id in existing_ids:
            continue
            
        # å¤„ç†æ•°æ®
        full_name = html.escape(item["full_name"])
        description = item["description"]
        description = html.escape(description.strip()) if description and description.strip() else 'no description'
        url = item["html_url"]
        created_at = item["created_at"]
        
        # æå–CVEç¼–å·ï¼ˆç®€åŒ–æ­£åˆ™å¤„ç†ï¼‰
        cve_match = re.search(regex, url)
        if not cve_match:
            cve_match = re.search(regex, description)
        
        cve = cve_match.group() if cve_match else "CVE Not Found"
        cve = cve.replace('_', '-')
        
        # æ·»åŠ åˆ°è¿”å›åˆ—è¡¨
        r_list.append({
            "id": id,
            "full_name": full_name,
            "description": description,
            "url": url,
            "created_at": created_at,
            "cve": cve
        })
        
        # å‡†å¤‡æ’å…¥æ•°æ®åº“
        to_insert.append({
            'id': id,
            'full_name': full_name,
            'description': description,
            'url': url,
            'created_at': created_at,
            'cve': cve.upper()
        })
    
    # æ‰¹é‡æ’å…¥æ•°æ®åº“ï¼ˆå¦‚æœæœ‰æ–°æ•°æ®ï¼‰
    if to_insert:
        # ä½¿ç”¨äº‹åŠ¡å’Œæ‰¹é‡æ’å…¥
        try:
            with CVE_DB._meta.database.atomic():
                CVE_DB.insert_many(to_insert).execute()
        except Exception:
            # å¦‚æœæ‰¹é‡æ’å…¥å¤±è´¥ï¼Œå°è¯•å•æ¡æ’å…¥ï¼ˆä½†è¿™ä¸æ˜¯ç†æƒ³æƒ…å†µï¼‰
            for data in to_insert:
                try:
                    CVE_DB.create(**data)
                except Exception:
                    pass
    
    # æŒ‰åˆ›å»ºæ—¶é—´æ’åº
    return sorted(r_list, key=lambda e: e['created_at'])

def init_others_file():
    """åˆå§‹åŒ–others.mdæ–‡ä»¶"""
    newline = f"""# å…¶ä»–æœªè¯†åˆ«CVEç¼–å·çš„ä»“åº“æŠ¥å‘Š

> Automatic monitor Github CVE using Github Actions 

## æŠ¥å‘Šä¿¡æ¯
- **ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- **æ•°æ®æ¥æº**: GitHubä»“åº“ï¼ˆæœªè¯†åˆ«CVEç¼–å·ï¼‰
- **è¯´æ˜**: æœ¬æŠ¥å‘ŠåŒ…å«åœ¨GitHubä¸Šæ‰¾åˆ°ä½†æœªèƒ½æå–æœ‰æ•ˆCVEç¼–å·çš„ä»“åº“ä¿¡æ¯

## ä»“åº“åˆ—è¡¨

| çŠ¶æ€ | ç›¸å…³ä»“åº“ | æè¿° | æ—¥æœŸ |
|:---|:---|:---|:---|
"""
    with open(os.path.join(PROJECT_ROOT, 'docs/others.md'), 'w', encoding='utf-8') as f:
        f.write(newline)
    f.close()

def write_others_file(new_contents):
    """ä¼˜åŒ–çš„othersæ–‡ä»¶å†™å…¥å‡½æ•°ï¼Œå‡å°‘I/Oæ“ä½œ"""
    # ä½¿ç”¨withè¯­å¥è‡ªåŠ¨å¤„ç†æ–‡ä»¶å…³é—­
    with open(os.path.join(PROJECT_ROOT, 'docs/others.md'), 'a', encoding='utf-8') as f:
        f.write(new_contents)

def main():
    # è·å–å½“å‰æ—¥æœŸ
    today = datetime.now()
    date_str = today.strftime("%Y%m%d")
    year = today.year
    
    # åˆå§‹åŒ–å…¨é‡æ•°æ®æ–‡ä»¶
    init_file()

    # åˆå§‹åŒ–æ¯æ—¥æŠ¥å‘Šæ–‡ä»¶
    daily_file_path = init_daily_file(date_str)
    
    # åˆå§‹åŒ–othersæ–‡ä»¶
    init_others_file()

    # æ”¶é›†æ•°æ®
    sorted_list = []
    today_list = []  # å­˜å‚¨å½“æ—¥æ•°æ®
    others_list = []  # å­˜å‚¨CVEç¼–å·ä¸ºç©ºçš„æ•°æ®
    
    # åˆå§‹åŒ–å¤±è´¥è®¡æ•°
    consecutive_failures = 0
    
    # é¦–å…ˆè·å–å½“å¹´çš„æ•°æ®ï¼ˆå½“æ—¥æ•°æ®ï¼‰
    item = get_info(year)
    if item and len(item) > 0:
        sorted_data = db_match(item)
        if sorted_data:
            # ç­›é€‰å½“æ—¥æ•°æ®
            for entry in sorted_data:
                try:
                    created_date = datetime.fromisoformat(entry["created_at"].replace("Z", "+00:00"))
                    created_date_str = created_date.strftime("%Y-%m-%d")
                    today_str = today.strftime("%Y-%m-%d")
                    if created_date_str == today_str:
                        today_list.append(entry)
                except Exception:
                    pass
            
            sorted_list.extend(sorted_data)
        
        # æœ€å°åŒ–ç­‰å¾…æ—¶é—´
        time.sleep(0.5)
    
    # å‡å°‘å†å²æ•°æ®è·å–ï¼Œä»…è·å–2å¹´å‰çš„æ•°æ®
    start_year = max(2020, year-1)
    end_year = max(2020, year-2)  # å‡å°‘ä¸º2å¹´
    
    # å¿«é€Ÿè·å–å†å²æ•°æ®
    for i in range(start_year, end_year-1, -1):
        # æœ€å°åŒ–ç­‰å¾…æ—¶é—´
        time.sleep(0.3)
        
        item = get_info(i)
        if item and len(item) > 0:
            sorted_data = db_match(item)
            if sorted_data:
                sorted_list.extend(sorted_data)
                consecutive_failures = 0
            else:
                consecutive_failures += 1
                if consecutive_failures >= 1:  # æ›´å¿«æ”¾å¼ƒå¤±è´¥çš„è¯·æ±‚
                    break
        else:
            consecutive_failures += 1
            if consecutive_failures >= 1:
                break
    
    print(f"âœ… å†å²æ•°æ®è·å–å®Œæˆ")
    
    # ç”Ÿæˆå…¨é‡æ•°æ®æŠ¥å‘Š
    cur = db.cursor()
    cur.execute("SELECT * FROM CVE_DB ORDER BY cve DESC;")
    result = cur.fetchall()
    
    # åˆ†ç¦»æœ‰CVEç¼–å·å’Œæ— CVEç¼–å·çš„æ•°æ®
    valid_cve_records = []
    others_records = []
    
    for row in result:
        if row[5].upper() == "CVE NOT FOUND":
            others_records.append(row)
        else:
            valid_cve_records.append(row)
    
    # å†™å…¥æŠ¥å‘Šå¤´éƒ¨
    newline = f"""# å…¨é‡ æƒ…æŠ¥é€Ÿé€’ æ•°æ®æŠ¥å‘Š

> Automatic monitor Github CVE using Github Actions 

## æŠ¥å‘Šä¿¡æ¯
- **ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- **æ•°æ®æ¥æº**: GitHub CVE æ•°æ®åº“
- **æ€»è®°å½•æ•°**: {len(valid_cve_records)}
- **å…¶ä»–è®°å½•æ•°**: {len(others_records)} (è¯¦è§ [others.md](./others.md))

## å…¨é‡æ•°æ®æŠ¥å‘Š

| CVE | ç›¸å…³ä»“åº“ï¼ˆpoc/expï¼‰ | æè¿° | æ—¥æœŸ |
|:---|:---|:---|:---|
"""
    write_file(newline, overwrite=True) # é¦–æ¬¡å†™å…¥æ—¶è¦†ç›–æ–‡ä»¶

    # å†™å…¥æœ‰æ•ˆçš„CVEè®°å½•
    for row in valid_cve_records:
        Publish_Date = row[4]
        Description = row[2].replace('|','-')
        newline = "| [" + row[5].upper() + "](https://www.cve.org/CVERecord?id=" + row[5].upper() + ") | [" + row[1] + "](" + row[3] + ") | " + Description + " | " + Publish_Date + "|\n"
        write_file(newline)
    
    # ç”Ÿæˆothers.mdæŠ¥å‘Š
    if len(others_records) > 0:
        for row in others_records:
            Publish_Date = row[4]
            Description = row[2].replace('|','-')
            newline = "| ğŸš« æœªè¯†åˆ« | [" + row[1] + "](" + row[3] + ") | " + Description + " | " + Publish_Date + "|\n"
            write_others_file(newline)
        
        # æ·»åŠ æŠ¥å‘Šå°¾éƒ¨
        footer = f"\n\n---\n\n**æŠ¥å‘Šç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}  \n**æ€»è®°å½•æ•°**: {len(others_records)}\n"
        write_others_file(footer)
    
    # ç”Ÿæˆå½“æ—¥æŠ¥å‘Š
    
    # è®°å½•åŸå§‹today_listé•¿åº¦
    original_today_list_len = len(today_list)
    print(f"ç”Ÿæˆå½“æ—¥ æƒ…æŠ¥é€Ÿé€’ æŠ¥å‘Šï¼Œå…± {len(today_list)} æ¡è®°å½•")
    
    # å¦‚æœå½“æ—¥æ²¡æœ‰æ•°æ®ï¼Œä½¿ç”¨æœ€è¿‘çš„æ•°æ®
    if len(today_list) == 0:
        print("å½“æ—¥æ— æ•°æ®ï¼Œå°è¯•è·å–æœ€è¿‘7å¤©çš„æ•°æ®...")
        # å…ˆå°è¯•è·å–æœ€è¿‘7å¤©çš„æ•°æ®
        cur = db.cursor()
        # è·å–7å¤©å†…çš„æ•°æ®
        from datetime import timedelta
        seven_days_ago = (today - timedelta(days=7)).strftime("%Y-%m-%d")
        cur.execute(f"SELECT * FROM CVE_DB WHERE created_at >= '{seven_days_ago}' ORDER BY created_at DESC;")
        recent_records = cur.fetchall()
        
        # å¦‚æœ7å¤©å†…æ²¡æœ‰æ•°æ®ï¼Œåˆ™è·å–æœ€è¿‘çš„10æ¡è®°å½•
        if len(recent_records) == 0:
            print("æœ€è¿‘7å¤©æ— æ•°æ®ï¼Œè·å–æœ€è¿‘10æ¡è®°å½•...")
            cur.execute("SELECT * FROM CVE_DB ORDER BY created_at DESC LIMIT 10;")
            recent_records = cur.fetchall()
        
        # è½¬æ¢ä¸ºä¸today_listç›¸åŒçš„æ ¼å¼
        for row in recent_records:
            today_list.append({
                "cve": row[5],
                "full_name": row[1],
                "description": row[2],
                "url": row[3],
                "created_at": row[4]
            })
        
        print(f"å½“æ—¥æ— æ•°æ®ï¼Œä½¿ç”¨æœ€è¿‘ {len(today_list)} æ¡è®°å½•")
    
    # å†™å…¥æ¯æ—¥æŠ¥å‘Šæ–‡ä»¶
    if len(today_list) > 0:
        print(f"æˆåŠŸå†™å…¥ {len(today_list)} æ¡è®°å½•åˆ°æ¯æ—¥ æƒ…æŠ¥é€Ÿé€’ æŠ¥å‘Š")

    # å†™å…¥æ¯æ—¥æŠ¥å‘Šï¼ˆè¿‡æ»¤æ‰CVE NOT FOUNDçš„è®°å½•ï¼‰
    valid_today_list = [entry for entry in today_list if entry["cve"].upper() != "CVE NOT FOUND"]
    
    for entry in valid_today_list:
        cve = entry["cve"]
        full_name = entry["full_name"]
        description = entry["description"].replace('|','-')
        url = entry["url"]
        created_at = entry["created_at"]

        newline = f"| [{cve.upper()}](https://www.cve.org/CVERecord?id={cve.upper()}) | [{full_name}]({url}) | {description} | {created_at}|\n"

        # å†™å…¥æ¯æ—¥æŠ¥å‘Šæ–‡ä»¶
        write_daily_file(daily_file_path, newline)

    # å¦‚æœæ˜¯ä½¿ç”¨æœ€è¿‘è®°å½•ï¼Œåˆ™åœ¨æŠ¥å‘Šä¸­å¢åŠ è¯´æ˜ (ç§»åŠ¨åˆ°æ­¤å¤„)
    if original_today_list_len == 0:
        with open(daily_file_path, 'a', encoding='utf-8') as f:
            f.write("\n\n> ç”±äºæ²¡æœ‰è·å–åˆ°å½“æ—¥æ•°æ®ï¼Œä½¿ç”¨è¿‘7å¤©è®°å½•\n\n")

    # æ›´æ–°ç´¢å¼•æ–‡ä»¶ï¼Œåˆ—å‡ºæ‰€æœ‰æ¯æ—¥æŠ¥å‘Š
    update_daily_index()

    # Statistics
    print("\nğŸ“Š ç”Ÿæˆç»Ÿè®¡æ•°æ®...")
    try:
        import sys
        # è·å–è„šæœ¬æ‰€åœ¨ç›®å½•çš„ç»å¯¹è·¯å¾„
        script_dir = os.path.dirname(os.path.abspath(__file__))
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨ - ä½¿ç”¨å°å†™çš„dataç›®å½•
        daily_dir = os.path.join(PROJECT_ROOT, 'docs', 'data', 'daily')
        stats_dir = os.path.join(PROJECT_ROOT, 'docs', 'data', 'statistics')
        os.makedirs(daily_dir, exist_ok=True)
        os.makedirs(stats_dir, exist_ok=True)
        
        # å…ˆè¿è¡Œæ•°æ®ç”Ÿæˆè„šæœ¬åˆ›å»ºæ±‡æ€»æ–‡ä»¶
        import subprocess
        print("ğŸ“Š æ­£åœ¨ç”Ÿæˆæ±‡æ€»æ•°æ®...")
        
        # æ„å»ºå‘½ä»¤å‚æ•°
        script_path = os.path.join(PROJECT_ROOT, 'scripts/enhanced_daily_data_generator.py')
        
        # å°è¯•ä½¿ç”¨ä¸åŒçš„Pythonè§£é‡Šå™¨è·¯å¾„
        python_executables = [sys.executable, 'python', 'python3']
        success = False
        
        for python_exe in python_executables:
            try:
                # ç›´æ¥è°ƒç”¨Pythonè§£é‡Šå™¨è¿è¡Œè„šæœ¬ï¼Œå‡å°‘è°ƒè¯•è¾“å‡º
                subprocess.run([python_exe, script_path],  # ç§»é™¤--fill-gapså‚æ•°ä»¥æé«˜æ€§èƒ½
                             check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=(os.name == 'nt'))
                success = True
                print("æ•°æ®æ±‡æ€»æ–‡ä»¶å·²ç”Ÿæˆ")
                break
            except Exception as e:
                # å¦‚æœä¸æ˜¯æœ€åä¸€ä¸ªå°è¯•ï¼Œç»§ç»­å°è¯•ä¸‹ä¸€ä¸ª
                if python_exe != python_executables[-1]:
                    continue
                else:
                    # åªåœ¨æ‰€æœ‰å°è¯•éƒ½å¤±è´¥æ—¶æ‰“å°é”™è¯¯
                    print(f"æ•°æ®æ±‡æ€»å¤±è´¥: {e}")
                    raise
        
        # å†è¿è¡Œç»Ÿè®¡ç”Ÿæˆè„šæœ¬
        print("ğŸ“ˆ æ­£åœ¨ç”ŸæˆWikiç»Ÿè®¡æ•°æ®...")
        stats_script_path = os.path.join(PROJECT_ROOT, 'scripts/generate_wiki_stats.py')
        
        for python_exe in python_executables:
            try:
                # ç›´æ¥è°ƒç”¨Pythonè§£é‡Šå™¨è¿è¡Œç»Ÿè®¡è„šæœ¬ï¼Œå‡å°‘è°ƒè¯•è¾“å‡º
                subprocess.run([python_exe, stats_script_path],
                             check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=(os.name == 'nt'))
                print("Wikiç»Ÿè®¡æ•°æ®å·²ç”Ÿæˆ")
                break
            except Exception as e:
                # å¦‚æœä¸æ˜¯æœ€åä¸€ä¸ªå°è¯•ï¼Œç»§ç»­å°è¯•ä¸‹ä¸€ä¸ª
                if python_exe != python_executables[-1]:
                    continue
                else:
                    # åªåœ¨æ‰€æœ‰å°è¯•éƒ½å¤±è´¥æ—¶æ‰“å°é”™è¯¯
                    print(f"ç»Ÿè®¡æ•°æ®ç”Ÿæˆå¤±è´¥: {e}")
                    raise
    except Exception as e:
        print(f"âš ï¸  ç»Ÿè®¡æ•°æ®ç”Ÿæˆè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        # ç»§ç»­æ‰§è¡Œï¼Œä¸ä¸­æ–­ä¸»æµç¨‹

if __name__ == "__main__":
    # init_file() # ç§»é™¤æ­¤è¡Œï¼Œå› ä¸ºå…¨é‡æŠ¥å‘Šçš„å†™å…¥ä¼šè¦†ç›–æ–‡ä»¶
    main()
