from functools import total_ordering
import requests
from peewee import *
from datetime import datetime
import html
import time
import random
import math
import re
import os
import locale
from pathlib import Path
import json
# å¯¼å…¥dotenvåº“ä»¥æ”¯æŒä».envæ–‡ä»¶è¯»å–ç¯å¢ƒå˜é‡
try:
    from dotenv import load_dotenv
    load_dotenv()  # åŠ è½½.envæ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡
    print("DEBUG: å·²åŠ è½½dotenvåº“å¹¶ä».envæ–‡ä»¶è¯»å–ç¯å¢ƒå˜é‡")
except ImportError:
    print("DEBUG: æœªå®‰è£…dotenvåº“ï¼Œè·³è¿‡ä».envæ–‡ä»¶è¯»å–ç¯å¢ƒå˜é‡")

# ç¡®å®šé¡¹ç›®æ ¹ç›®å½•
def get_project_root():
    """
    è·å–é¡¹ç›®æ ¹ç›®å½•çš„ç»å¯¹è·¯å¾„ï¼Œå¤„ç†åµŒå¥—ç›®å½•æƒ…å†µ
    è§£å†³GitHub Actionsç¯å¢ƒä¸­çš„ç›®å½•åµŒå¥—é—®é¢˜
    """
    # è·å–å½“å‰æ–‡ä»¶æ‰€åœ¨ç›®å½•ï¼ˆåŒ…å«main.pyçš„ç›®å½•ï¼‰
    current_file_path = os.path.abspath(__file__)
    current_dir = os.path.dirname(current_file_path)
    print(f"DEBUG: å½“å‰æ–‡ä»¶è·¯å¾„: {current_file_path}")
    print(f"DEBUG: å½“å‰ç›®å½•: {current_dir}")
    
    # æƒ…å†µ1: æ£€æŸ¥å½“å‰ç›®å½•æ˜¯å¦å·²ç»åŒ…å«æ‰€æœ‰å¿…è¦æ–‡ä»¶/ç›®å½•
    if os.path.exists(os.path.join(current_dir, 'main.py')) and \
       os.path.exists(os.path.join(current_dir, 'docs')) and \
       os.path.exists(os.path.join(current_dir, 'db')):
        print(f"DEBUG: å½“å‰ç›®å½•å·²åŒ…å«æ‰€æœ‰å¿…è¦æ–‡ä»¶/ç›®å½•")
        return current_dir
    
    # æƒ…å†µ2: æ£€æŸ¥GitHub Actionså…¸å‹åµŒå¥—ç»“æ„
    # åœ¨GitHub Actionsä¸­ï¼Œä»£ç é€šå¸¸åœ¨ /home/runner/work/repo_name/repo_name ä¸­
    if 'runner' in current_dir and 'work' in current_dir:
        # æŸ¥æ‰¾æœ€åä¸€ä¸ªé¡¹ç›®ç›®å½•å
        parts = current_dir.split(os.path.sep)
        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨åµŒå¥—çš„é¡¹ç›®ç›®å½•
        for i, part in enumerate(parts):
            if part and i < len(parts) - 1 and parts[i] == parts[i+1]:
                # æ‰¾åˆ°åµŒå¥—ç›®å½•ï¼Œè¿”å›å®Œæ•´è·¯å¾„
                nested_path = os.path.sep.join(parts[:i+2])
                if os.path.exists(os.path.join(nested_path, 'main.py')):
                    print(f"DEBUG: æ£€æµ‹åˆ°GitHub ActionsåµŒå¥—ç›®å½•ç»“æ„: {nested_path}")
                    return nested_path
    
    # æƒ…å†µ3: å°è¯•å‘ä¸‹æŸ¥æ‰¾ï¼ˆé’ˆå¯¹GitHub Actionsç¯å¢ƒï¼Œå¯èƒ½å½“å‰åœ¨workç›®å½•è€Œä¸æ˜¯å®é™…ä»£ç ç›®å½•ï¼‰
    # æ£€æŸ¥å½“å‰ç›®å½•ä¸‹æ˜¯å¦æœ‰åä¸ºgithub_cve_monitorçš„å­ç›®å½•
    possible_nested_dir = os.path.join(current_dir, 'github_cve_monitor')
    if os.path.exists(possible_nested_dir) and \
       os.path.exists(os.path.join(possible_nested_dir, 'main.py')) and \
       os.path.exists(os.path.join(possible_nested_dir, 'docs')) and \
       os.path.exists(os.path.join(possible_nested_dir, 'db')):
        print(f"DEBUG: æ£€æµ‹åˆ°å‘ä¸‹åµŒå¥—çš„é¡¹ç›®ç›®å½•: {possible_nested_dir}")
        return possible_nested_dir
    
    # æƒ…å†µ4: é€çº§å‘ä¸ŠæŸ¥æ‰¾
    test_dir = current_dir
    max_depth = 5  # è®¾ç½®æœ€å¤§æŸ¥æ‰¾æ·±åº¦
    
    for depth in range(max_depth):
        # å‘ä¸Šä¸€çº§ç›®å½•
        parent_dir = os.path.dirname(test_dir)
        if parent_dir == test_dir:  # åˆ°è¾¾æ–‡ä»¶ç³»ç»Ÿæ ¹ç›®å½•
            print(f"DEBUG: åˆ°è¾¾æ–‡ä»¶ç³»ç»Ÿæ ¹ç›®å½•")
            break
        
        print(f"DEBUG: å‘ä¸ŠæŸ¥æ‰¾å±‚çº§ {depth+1}: {parent_dir}")
        
        # æ£€æŸ¥çˆ¶ç›®å½•æ˜¯å¦åŒ…å«æ‰€æœ‰å¿…è¦æ–‡ä»¶/ç›®å½•
        if os.path.exists(os.path.join(parent_dir, 'main.py')) and \
           os.path.exists(os.path.join(parent_dir, 'docs')) and \
           os.path.exists(os.path.join(parent_dir, 'db')):
            print(f"DEBUG: åœ¨çˆ¶ç›®å½•æ‰¾åˆ°é¡¹ç›®æ ¹ç›®å½•: {parent_dir}")
            return parent_dir
        
        test_dir = parent_dir
    
    # å¦‚æœæ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥ï¼Œè¿”å›å½“å‰ç›®å½•ä½œä¸ºæœ€åæ‰‹æ®µ
    print(f"DEBUG: æ— æ³•ç¡®å®šé¡¹ç›®æ ¹ç›®å½•ï¼Œè¿”å›å½“å‰ç›®å½•ä½œä¸ºé»˜è®¤å€¼")
    return current_dir

# è·å–é¡¹ç›®æ ¹ç›®å½•
PROJECT_ROOT = get_project_root()
print(f"DEBUG: é¡¹ç›®æ ¹ç›®å½•: {PROJECT_ROOT}")


# è®¾ç½®ä¸­æ–‡ç¯å¢ƒ
try:
    locale.setlocale(locale.LC_ALL, 'zh_CN.UTF-8')
except:
    try:
        locale.setlocale(locale.LC_ALL, 'Chinese_China.936')
    except:
        pass  # å¦‚æœè®¾ç½®å¤±è´¥ï¼Œä½¿ç”¨ç³»ç»Ÿé»˜è®¤

db = SqliteDatabase(os.path.join(PROJECT_ROOT, "db/cve.sqlite"))

class CVE_DB(Model):
    id = IntegerField()
    full_name = CharField(max_length=1024)
    description = CharField(max_length=4098)
    url = CharField(max_length=1024)
    created_at = CharField(max_length=128)
    cve = CharField(max_length=64)

    class Meta:
        database = db

db.connect()
db.create_tables([CVE_DB])

def init_file():
    newline = "# Github CVE Monitor\n\n> Automatic monitor github cve using Github Actions \n\n Last generated : {}\n\n| CVE | ç›¸å…³ä»“åº“ï¼ˆpoc/expï¼‰ | æè¿° | æ—¥æœŸ |\n|---|---|---|---|\n".format(datetime.now())
    with open(os.path.join(PROJECT_ROOT, 'docs/README.md'),'w', encoding='utf-8') as f:
        f.write(newline) 
    f.close()

def write_file(new_contents, overwrite=False):
    mode = 'w' if overwrite else 'a'
    with open(os.path.join(PROJECT_ROOT, 'docs/README.md'), mode, encoding='utf-8') as f:
        f.write(new_contents)
    f.close()

def init_daily_file(date_str):
    """åˆå§‹åŒ–æ¯æ—¥æŠ¥å‘Šæ–‡ä»¶"""
    # åˆ›å»ºæ—¥æœŸç›®å½•
    today = datetime.now()
    year = today.year
    week_number = today.strftime("%W")
    month = today.strftime("%m")
    day = today.strftime("%d")
    
    # åˆ›å»ºç›®å½•ç»“æ„ /reports/weekly/YYYY-W-mm-dd
    dir_path = os.path.join(PROJECT_ROOT, f"docs/reports/weekly/{year}-W{week_number}-{month}-{day}")
    Path(dir_path).mkdir(parents=True, exist_ok=True)
    
    # åˆ›å»ºæ¯æ—¥æŠ¥å‘Šæ–‡ä»¶
    file_path = os.path.join(dir_path, f"daily_{date_str}.md")
    newline = f"""# æ¯æ—¥ æƒ…æŠ¥é€Ÿé€’ æŠ¥å‘Š ({date_str})

> Automatic monitor Github CVE using Github Actions 

## æŠ¥å‘Šä¿¡æ¯
- **ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- **æ•°æ®æ¥æº**: GitHub CVE æ•°æ®åº“

## ä»Šæ—¥ æƒ…æŠ¥é€Ÿé€’

| CVE | ç›¸å…³ä»“åº“ï¼ˆpoc/expï¼‰ | æè¿° | æ—¥æœŸ |
|:---|:---|:---|:---|
"""
    
    with open(file_path, 'w', encoding='utf-8') as f:
        f.write(newline)
    
    return file_path

def write_daily_file(file_path, new_contents):
    """å†™å…¥æ¯æ—¥ æƒ…æŠ¥é€Ÿé€’ æŠ¥å‘Šæ–‡ä»¶"""
    # ç¡®ä¿æ–‡ä»¶è·¯å¾„æ­£ç¡®
    if not os.path.isabs(file_path):
        file_path = os.path.join(PROJECT_ROOT, file_path)
    with open(file_path, 'a', encoding='utf-8') as f:
        f.write(new_contents)
    f.close()

def update_daily_index():
    """æ›´æ–°æ¯æ—¥ æƒ…æŠ¥é€Ÿé€’ æŠ¥å‘Šç´¢å¼•æ–‡ä»¶"""
    data_dir = Path(os.path.join(PROJECT_ROOT, "docs/reports/weekly"))
    if not data_dir.exists():
        return
    
    # åˆ›å»ºç´¢å¼•æ–‡ä»¶
    index_path = data_dir / "index.md"
    with open(index_path, 'w', encoding='utf-8') as f:
        f.write("# æ¯æ—¥ æƒ…æŠ¥é€Ÿé€’ æŠ¥å‘Šç´¢å¼•\n\n")
        f.write("> Automatic monitor Github CVE using Github Actions\n\n")
        f.write("## å¯ç”¨æŠ¥å‘Š\n\n")
    
    # éå†æ‰€æœ‰æ—¥æœŸç›®å½•
    date_dirs = sorted([d for d in data_dir.glob("*-W*-*-*")], reverse=True)
    
    for date_dir in date_dirs:
        dir_name = date_dir.name
        with open(index_path, 'a', encoding='utf-8') as f:
            f.write(f"### {dir_name}\n\n")
        
        # éå†è¯¥ç›®å½•ä¸‹çš„æ‰€æœ‰dailyæŠ¥å‘Š
        daily_files = sorted([f for f in date_dir.glob("daily_*.md")], reverse=True)
        
        for daily_file in daily_files:
            file_name = daily_file.name
            relative_path = f"data/{date_dir.name}/{file_name}"
            date_str = file_name.replace("daily_", "").replace(".md", "")
            
            # æ ¼å¼åŒ–æ—¥æœŸæ˜¾ç¤º
            try:
                formatted_date = f"{date_str[:4]}-{date_str[4:6]}-{date_str[6:]}"
            except:
                formatted_date = date_str
            
            with open(index_path, 'a', encoding='utf-8') as f:
                f.write(f"- [{formatted_date} æ¯æ—¥æŠ¥å‘Š]({relative_path})\n")
        
        with open(index_path, 'a', encoding='utf-8') as f:
            f.write("\n")
    
    # æ›´æ–°ä¾§è¾¹æ ï¼Œæ·»åŠ æ¯æ—¥æŠ¥å‘Šé“¾æ¥
    update_sidebar()

def update_sidebar():
    """æ›´æ–°ä¾§è¾¹æ ï¼Œæ·»åŠ æ¯æ—¥æŠ¥å‘Šé“¾æ¥"""
    sidebar_path = Path(os.path.join(PROJECT_ROOT, "docs/_sidebar.md"))
    if not sidebar_path.exists():
        return
    
    # è¯»å–ç°æœ‰ä¾§è¾¹æ å†…å®¹
    with open(sidebar_path, 'r', encoding='utf-8') as f:
        lines = f.readlines()
    
    # æ£€æŸ¥æ˜¯å¦å·²æœ‰æ¯æ—¥æŠ¥å‘Šé“¾æ¥
    daily_report_exists = False
    for line in lines:
        if "æ¯æ—¥æŠ¥å‘Š" in line:
            daily_report_exists = True
            break
    
    # å¦‚æœæ²¡æœ‰æ¯æ—¥æŠ¥å‘Šé“¾æ¥ï¼Œæ·»åŠ åˆ°ä¾§è¾¹æ 
    if not daily_report_exists:
        # æ‰¾åˆ°åˆé€‚çš„ä½ç½®æ’å…¥é“¾æ¥
        new_lines = []
        for line in lines:
            new_lines.append(line)
            # åœ¨ä¸»é¡µé“¾æ¥åæ·»åŠ æ¯æ—¥æŠ¥å‘Šé“¾æ¥
            if "- [ä¸»é¡µ](README.md)" in line or "- [Home](README.md)" in line:
                new_lines.append("- [æ¯æ—¥æŠ¥å‘Š](/data/index.md)\n")
        
        # å†™å›æ–‡ä»¶
        with open(sidebar_path, 'w', encoding='utf-8') as f:
            f.writelines(new_lines)

def load_config():
    """ä»é…ç½®æ–‡ä»¶åŠ è½½é…ç½®ä¿¡æ¯"""
    config_paths = [
        os.path.join(PROJECT_ROOT, "docs/config/config.json"),
        os.path.join(PROJECT_ROOT, "docs/data/config.json"),
        os.path.join(PROJECT_ROOT, "docs/config.json"),
        os.path.join(PROJECT_ROOT, "config.json")
    ]
    
    for config_path in config_paths:
        if os.path.exists(config_path):
            try:
                with open(config_path, 'r', encoding='utf-8') as f:
                    config = json.load(f)
                    return config
            except Exception as e:
                print(f"è­¦å‘Š: æ— æ³•è¯»å–é…ç½®æ–‡ä»¶ {config_path}: {e}")
    
    return {}

def get_github_token():
    """è·å–GitHub Tokenï¼Œä¼˜å…ˆçº§ï¼šç¯å¢ƒå˜é‡(.envæˆ–ç³»ç»Ÿç¯å¢ƒå˜é‡) > é…ç½®æ–‡ä»¶"""
    # é¦–å…ˆæ£€æŸ¥ç¯å¢ƒå˜é‡ï¼ˆä¼šè‡ªåŠ¨åŒ…æ‹¬ä».envæ–‡ä»¶åŠ è½½çš„å˜é‡ï¼‰
    github_token = os.environ.get('GITHUB_TOKEN')
    if github_token:
        print(f"DEBUG: ä»ç¯å¢ƒå˜é‡è·å–åˆ°GITHUB_TOKEN")
        print(f"DEBUG: Tokené•¿åº¦: {len(github_token)}")
        # ä¸è¦æ‰“å°å®Œæ•´çš„tokenï¼Œä½†å¯ä»¥æ‰“å°å‰å‡ ä¸ªå­—ç¬¦æ¥ç¡®è®¤
        if len(github_token) > 5:
            print(f"DEBUG: Tokenå‰ç¼€: {github_token[:5]}...")
        return github_token
    
    # ç„¶åæ£€æŸ¥é…ç½®æ–‡ä»¶
    config = load_config()
    github_token = config.get('github_token')
    if github_token and github_token != "your_token_here":
        print(f"DEBUG: ä»é…ç½®æ–‡ä»¶è·å–åˆ°github_token")
        print(f"DEBUG: Tokené•¿åº¦: {len(github_token)}")
        if len(github_token) > 5:
            print(f"DEBUG: Tokenå‰ç¼€: {github_token[:5]}...")
        return github_token
    
    print("DEBUG: æœªæ‰¾åˆ°æœ‰æ•ˆçš„GitHub Token")
    print("DEBUG: æ‚¨å¯ä»¥åœ¨é¡¹ç›®æ ¹ç›®å½•åˆ›å»º.envæ–‡ä»¶ï¼Œå¹¶æ·»åŠ GITHUB_TOKEN=your_token_here")
    return None

def get_info(year):
    """
    è·å–æŒ‡å®šå¹´ä»½çš„CVEç›¸å…³GitHubä»“åº“ä¿¡æ¯
    åŸºäºåŸå§‹ä»£ç çš„ç®€åŒ–ç‰ˆæœ¬ï¼Œä¿ç•™åŸºæœ¬åŠŸèƒ½ä½†å‡å°‘å¤æ‚æ€§
    """
    try:
        all_items = []
        page = 1
        per_page = 100  # é»˜è®¤æ¯é¡µ100æ¡ï¼Œæœ‰tokenæ—¶ä½¿ç”¨
        github_token = get_github_token()
        headers = {'User-Agent': 'CVE-Monitor-App/1.0 (+https://github.com/adminlove520/github_cve_monitor)', 'Accept': 'application/json'}

        if github_token:
            print(f"DEBUG: GITHUB_TOKEN is set. Value: {github_token[:5]}...")
            headers['Authorization'] = f'token {github_token}'
            print(f"Using GitHub Token for authentication (Year: {year})")
        else:
            print("DEBUG: GITHUB_TOKEN is NOT set.")
            per_page = 30  # æ— tokenæ—¶æ¯é¡µ30æ¡
            print(f"No GitHub Token found, using unauthenticated request (Year: {year})")

        max_pages = 10  # é™åˆ¶æœ€å¤§é¡µæ•°
        max_retries = 2  # å‡å°‘é‡è¯•æ¬¡æ•°ï¼Œé¿å…é•¿æ—¶é—´ç­‰å¾…
        
        while page <= max_pages:
            api = f"https://api.github.com/search/repositories?q=CVE-{year}&sort=updated&page={page}&per_page={per_page}"
            print(f"DEBUG: æ­£åœ¨è·å–å¹´ä»½ {year} çš„ç¬¬ {page}/{max_pages} é¡µæ•°æ®")
            
            # å¦‚æœå·²ç»è¾¾åˆ°æœ€å¤§é¡µæ•°ï¼Œç›´æ¥è¿”å›ç»“æœ
            if page > max_pages:
                print(f"âš ï¸ å·²è¾¾åˆ°æœ€å¤§é¡µæ•°é™åˆ¶ ({max_pages})ï¼Œç»“æŸè¯·æ±‚")
                print(f"æ€»å…±è·å–åˆ° {len(all_items)} æ¡æ•°æ®")
                return all_items
                
            # ç®€å•å»¶è¿Ÿ - ä¼˜åŒ–ç­‰å¾…æ—¶é—´ï¼Œæœ‰tokenæ—¶å‡å°‘ç­‰å¾…
            if page > 1:
                wait_time = 2 if github_token else 4
                print(f"DEBUG: ç­‰å¾… {wait_time} ç§’åè¯·æ±‚ä¸‹ä¸€é¡µ")
                time.sleep(wait_time)
            
            # ä½¿ç”¨ç®€å•çš„è¯·æ±‚æ–¹å¼
            retry_count = 0
            while retry_count < max_retries:
                try:
                    print(f"DEBUG: å°è¯•è¯·æ±‚ç¬¬ {page} é¡µ (å°è¯• {retry_count+1}/{max_retries})")
                    response = requests.get(api, headers=headers, timeout=15)
                    
                    # æ‰“å°å“åº”çŠ¶æ€å’Œé€Ÿç‡é™åˆ¶ä¿¡æ¯
                    print(f"DEBUG: APIè¯·æ±‚çŠ¶æ€ç : {response.status_code}")
                    if 'X-RateLimit-Remaining' in response.headers:
                        remaining = response.headers.get('X-RateLimit-Remaining')
                        limit = response.headers.get('X-RateLimit-Limit')
                        print(f"API Rate Limit: {remaining}/{limit}")
                    
                    # å¤„ç†å“åº”
                    if response.status_code == 200:
                        try:
                            data = response.json()
                            if 'items' in data:
                                items = data['items']
                                if items:
                                    all_items.extend(items)
                                    print(f"âœ… æˆåŠŸè·å–ç¬¬ {page} é¡µæ•°æ®ï¼Œå…± {len(items)} æ¡")
                                    
                                    # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°GitHub APIçš„1000æ¡ç»“æœé™åˆ¶
                                    if len(all_items) >= 1000:
                                        print(f"âœ… å·²è¾¾åˆ°GitHub Search APIçš„1000æ¡ç»“æœé™åˆ¶")
                                        print(f"æ€»å…±è·å–åˆ° {len(all_items)} æ¡æ•°æ®")
                                        return all_items  # ç¡®ä¿è¿”å›å¹¶é€€å‡ºå‡½æ•°
                                        
                                    # æ£€æŸ¥æ˜¯å¦æœ‰ä¸‹ä¸€é¡µ
                                    if len(items) < per_page:
                                        print(f"âœ… å·²è·å–æ‰€æœ‰æ•°æ®ï¼Œæ²¡æœ‰æ›´å¤šé¡µé¢")
                                        return all_items
                                    
                                    # ç»§ç»­ä¸‹ä¸€é¡µ
                                    page += 1
                                    break  # æˆåŠŸè·å–æ•°æ®ï¼Œè·³å‡ºé‡è¯•å¾ªç¯
                                else:
                                    print(f"âš ï¸ ç¬¬ {page} é¡µæ²¡æœ‰æ•°æ®ï¼Œç»“æŸè¯·æ±‚")
                                    return all_items
                            else:
                                print(f"âš ï¸ è­¦å‘Š: å“åº”ä¸­æ²¡æœ‰ 'items' å­—æ®µ")
                                retry_count += 1
                                time.sleep(3)
                        except json.JSONDecodeError:
                            print(f"âŒ é”™è¯¯: æ— æ³•è§£æJSONå“åº”")
                            retry_count += 1
                            time.sleep(3)
                    
                    # å¤„ç†é€Ÿç‡é™åˆ¶
                    elif response.status_code == 403:
                        print(f"âš ï¸ è­¦å‘Š: è¯·æ±‚è¢«æ‹’ç» (403)ï¼Œå¯èƒ½æ˜¯é€Ÿç‡é™åˆ¶")
                        if 'X-RateLimit-Reset' in response.headers:
                            reset_time = response.headers.get('X-RateLimit-Reset')
                            reset_seconds = int(reset_time) - int(time.time())
                            if reset_seconds > 0 and reset_seconds < 60:
                                print(f"ç­‰å¾… {reset_seconds} ç§’åç»§ç»­...")
                                time.sleep(reset_seconds + 2)
                                retry_count += 1
                            else:
                                print(f"âŒ é”™è¯¯: é€Ÿç‡é™åˆ¶é‡ç½®æ—¶é—´è¿‡é•¿ï¼Œè·³è¿‡æ­¤é¡µ")
                                page += 1  # è·³è¿‡å½“å‰é¡µ
                                break
                        else:
                            time.sleep(10)
                            retry_count += 1
                    
                    # å…¶ä»–é”™è¯¯
                    else:
                        print(f"âŒ é”™è¯¯: è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                        retry_count += 1
                        time.sleep(3)
                
                except requests.exceptions.Timeout:
                    print(f"âŒ é”™è¯¯: è¯·æ±‚è¶…æ—¶ï¼Œå°è¯•é‡è¯•")
                    retry_count += 1
                    time.sleep(3)
                
                except requests.exceptions.ConnectionError:
                    print(f"âŒ é”™è¯¯: è¿æ¥é”™è¯¯ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥")
                    retry_count += 1
                    time.sleep(5)
                
                except Exception as e:
                    print(f"âŒ é”™è¯¯: è¯·æ±‚å‘ç”Ÿå¼‚å¸¸: {e}")
                    retry_count += 1
                    time.sleep(3)
            
            # å¦‚æœé‡è¯•æ¬¡æ•°è¾¾åˆ°ä¸Šé™ä»æœªæˆåŠŸï¼Œè·³è¿‡å½“å‰é¡µ
            if retry_count >= max_retries:
                print(f"âš ï¸ è­¦å‘Š: ç¬¬ {page} é¡µå¤šæ¬¡å°è¯•å¤±è´¥ï¼Œè·³è¿‡æ­¤é¡µ")
                page += 1
        
        print(f"æ€»å…±è·å–åˆ° {len(all_items)} æ¡æ•°æ®")
        return all_items
    
    except Exception as e:
        print(f"âŒ é”™è¯¯: get_info å‡½æ•°å‘ç”Ÿå¼‚å¸¸: {e}")
        return []  # è¿”å›ç©ºåˆ—è¡¨è€Œä¸æ˜¯Noneï¼Œé¿å…åç»­å¤„ç†å‡ºé”™


def db_match(items):
    r_list = []
    regex = r"[Cc][Vv][Ee][-_]\d{4}[-_]\d{4,7}"
    cve = ''
    for item in items:
        id = item["id"]
        if CVE_DB.select().where(CVE_DB.id == id).count() != 0:
            continue
        full_name = html.escape(item["full_name"])
        description = item["description"]
        if description == "" or description == None:
            description = 'no description'
        else:
            description = html.escape(description.strip())
        url = item["html_url"]
### EXTRACT CVE 
        matches = re.finditer(regex, url, re.MULTILINE)
        for matchNum, match in enumerate(matches, start=1):
            cve = match.group()
        if not cve:
            matches = re.finditer(regex, description, re.MULTILINE)
            cve = "CVE Not Found"
            for matchNum, match in enumerate(matches, start=1):
                cve = match.group()
### 
        created_at = item["created_at"]
        r_list.append({
            "id": id,
            "full_name": full_name,
            "description": description,
            "url": url,
            "created_at": created_at,
            "cve": cve.replace('_','-')
        })
        CVE_DB.create(id=id,
                      full_name=full_name,
                      description=description,
                      url=url,
                      created_at=created_at,
                      cve=cve.upper().replace('_','-'))

    return sorted(r_list, key=lambda e: e.__getitem__('created_at'))

def init_others_file():
    """åˆå§‹åŒ–others.mdæ–‡ä»¶"""
    newline = f"""# å…¶ä»–æœªè¯†åˆ«CVEç¼–å·çš„ä»“åº“æŠ¥å‘Š

> Automatic monitor Github CVE using Github Actions 

## æŠ¥å‘Šä¿¡æ¯
- **ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- **æ•°æ®æ¥æº**: GitHubä»“åº“ï¼ˆæœªè¯†åˆ«CVEç¼–å·ï¼‰
- **è¯´æ˜**: æœ¬æŠ¥å‘ŠåŒ…å«åœ¨GitHubä¸Šæ‰¾åˆ°ä½†æœªèƒ½æå–æœ‰æ•ˆCVEç¼–å·çš„ä»“åº“ä¿¡æ¯

## ä»“åº“åˆ—è¡¨

| çŠ¶æ€ | ç›¸å…³ä»“åº“ | æè¿° | æ—¥æœŸ |
|:---|:---|:---|:---|
"""
    with open(os.path.join(PROJECT_ROOT, 'docs/others.md'), 'w', encoding='utf-8') as f:
        f.write(newline)
    f.close()

def write_others_file(new_contents):
    """å†™å…¥others.mdæ–‡ä»¶"""
    with open(os.path.join(PROJECT_ROOT, 'docs/others.md'), 'a', encoding='utf-8') as f:
        f.write(new_contents)
    f.close()

def main():
    # è·å–å½“å‰æ—¥æœŸ
    today = datetime.now()
    date_str = today.strftime("%Y%m%d")
    year = today.year
    
    # åˆå§‹åŒ–å…¨é‡æ•°æ®æ–‡ä»¶
    init_file()

    # åˆå§‹åŒ–æ¯æ—¥æŠ¥å‘Šæ–‡ä»¶
    daily_file_path = init_daily_file(date_str)
    
    # åˆå§‹åŒ–othersæ–‡ä»¶
    init_others_file()

    # æ”¶é›†æ•°æ®
    sorted_list = []
    today_list = []  # å­˜å‚¨å½“æ—¥æ•°æ®
    others_list = []  # å­˜å‚¨CVEç¼–å·ä¸ºç©ºçš„æ•°æ®
    
    # é¦–å…ˆè·å–å½“å¹´çš„æ•°æ®ï¼ˆå½“æ—¥æ•°æ®ï¼‰
    print(f"è·å–å½“å¹´ ({year}) çš„CVEæ•°æ®...")
    item = get_info(year)
    if item is not None and len(item) > 0:
        print(f"å¹´ä»½: {year} : è·å–åˆ° {len(item)} æ¡åŸå§‹æ•°æ®")
        sorted_data = db_match(item)
        if len(sorted_data) != 0:
            print(f"å¹´ä»½ {year} : æ›´æ–° {len(sorted_data)} æ¡è®°å½•")
            
            # ç­›é€‰å½“æ—¥æ•°æ®
            for entry in sorted_data:
                try:
                    created_date = datetime.fromisoformat(entry["created_at"].replace("Z", "+00:00"))
                    # åˆ¤æ–­æ˜¯å¦ä¸ºå½“æ—¥æ•°æ®ï¼ˆä½¿ç”¨æ—¥æœŸå­—ç¬¦ä¸²æ¯”è¾ƒï¼Œè€ƒè™‘åˆ°2025-09-22T13:53:14Zè¿™æ ·çš„æ ¼å¼ï¼‰
                    # æ³¨æ„ï¼šè¿™é‡Œéœ€è¦ä½¿ç”¨created_dateçš„æ—¥æœŸï¼Œä¸è½¬æ¢ä¸ºæœ¬åœ°æ—¶é—´
                    created_date_str = created_date.strftime("%Y-%m-%d")
                    today_str = today.strftime("%Y-%m-%d")
                    if created_date_str == today_str:
                        today_list.append(entry)
                except Exception as e:
                    print(f"æ—¥æœŸè§£æé”™è¯¯: {e}")
            
            sorted_list.extend(sorted_data)
        
        # éšæœºç­‰å¾…ä»¥é¿å…APIé™åˆ¶ - ä¼˜åŒ–ç­‰å¾…æ—¶é—´
        count = random.randint(2, 8)  # å‡å°‘ç­‰å¾…æ—¶é—´
        time.sleep(count)
    
    # è·å–å†å²æ•°æ®
    # é™åˆ¶å¹´ä»½èŒƒå›´åˆ°2020-2025ï¼Œå› ä¸ºä¹‹å‰çš„æ•°æ®ä»·å€¼è¾ƒå°
    start_year = max(2020, year-1)  # ä¸æ—©äº2020å¹´
    end_year = max(2020, year-5)    # æœ€å¤šè·å–5å¹´å‰çš„æ•°æ®ï¼Œä½†ä¸æ—©äº2020å¹´
    
    print(f"ğŸ” å¼€å§‹è·å–å†å²æ•°æ®ï¼ˆ{start_year}å¹´ åˆ° {end_year}å¹´ï¼‰")
    
    # è·Ÿè¸ªè¿ç»­å¤±è´¥æ¬¡æ•°ï¼Œé¿å…æ— é™é‡è¯•
    consecutive_failures = 0
    max_consecutive_failures = 2
    
    for i in range(start_year, end_year-1, -1):
        print(f"ğŸ“… æ­£åœ¨å¤„ç†å¹´ä»½: {i}")
        
        try:
            # æ·»åŠ ç”¨æˆ·å‹å¥½çš„è¿›åº¦æŒ‡ç¤º
            year_progress = (start_year - i + 1) / (start_year - end_year + 1)
            print(f"ğŸ“Š è¿›åº¦: {year_progress:.1%}")
            
            # ä¼˜åŒ–ï¼šå¢åŠ APIè°ƒç”¨çš„ç”¨æˆ·ä»£ç†æ ‡è¯†
            headers['User-Agent'] = 'CVE-Monitor-App/1.0 (+https://github.com/adminlove520/github_cve_monitor)'
            
            item = get_info(i)
            
            # æ£€æŸ¥æ•°æ®è·å–ç»“æœ
            if item is None:
                print(f"âŒ å¹´ä»½ {i} è·å–æ•°æ®å¤±è´¥ï¼Œè·³è¿‡")
                consecutive_failures += 1
                # å¦‚æœè¿ç»­å¤±è´¥æ¬¡æ•°è¿‡å¤šï¼Œå¯èƒ½æ˜¯APIé—®é¢˜ï¼Œæš‚åœæ›´é•¿æ—¶é—´
                if consecutive_failures >= max_consecutive_failures:
                    print(f"âš ï¸  è¿ç»­ {consecutive_failures} ä¸ªå¹´ä»½è·å–å¤±è´¥ï¼Œä¼‘æ¯æ›´é•¿æ—¶é—´...")
                    time.sleep(random.randint(30, 60))
                else:
                    time.sleep(random.randint(5, 10))
                continue
            
            consecutive_failures = 0  # é‡ç½®å¤±è´¥è®¡æ•°
            
            if len(item) == 0:
                print(f"ğŸ“­ å¹´ä»½ {i} æ²¡æœ‰è·å–åˆ°æ–°æ•°æ®")
                time.sleep(random.randint(3, 5))
                continue
            
            print(f"âœ… å¹´ä»½: {i} : è·å–åˆ° {len(item)} æ¡åŸå§‹æ•°æ®")
            
            # å¤„ç†æ•°æ®åŒ¹é…
            sorted_data = db_match(item)
            if len(sorted_data) != 0:
                print(f"ğŸ“‹ å¹´ä»½ {i} : æ›´æ–° {len(sorted_data)} æ¡è®°å½•")
                sorted_list.extend(sorted_data)
            else:
                print(f"ğŸ“ å¹´ä»½ {i} : æ²¡æœ‰éœ€è¦æ›´æ–°çš„æ–°è®°å½•")
            
            # æ ¹æ®è·å–åˆ°çš„æ•°æ®é‡è°ƒæ•´ç­‰å¾…æ—¶é—´ - ä¼˜åŒ–ç­‰å¾…æ—¶é—´
            if len(item) > 50:
                wait_time = random.randint(4, 8)  # å‡å°‘ç­‰å¾…æ—¶é—´
                print(f"ğŸ“Š æ•°æ®é‡è¾ƒå¤§ï¼Œç­‰å¾… {wait_time} ç§’...")
            else:
                wait_time = random.randint(2, 5)  # å‡å°‘ç­‰å¾…æ—¶é—´
                print(f"ğŸ“Š æ•°æ®é‡é€‚ä¸­ï¼Œç­‰å¾… {wait_time} ç§’...")
            
            time.sleep(wait_time)
            
        except Exception as e:
            print(f"âŒ å¤„ç†å¹´ä»½ {i} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            import traceback
            print(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
            consecutive_failures += 1
            
            # å‡ºé”™åç­‰å¾…æ›´é•¿æ—¶é—´å†ç»§ç»­ - ä¼˜åŒ–ç­‰å¾…æ—¶é—´
            error_wait_time = random.randint(5, 10)  # å‡å°‘ç­‰å¾…æ—¶é—´
            print(f"â±ï¸  å‡ºé”™åç­‰å¾… {error_wait_time} ç§’å†ç»§ç»­...")
            time.sleep(error_wait_time)
            
            # å¦‚æœè¿ç»­å¤±è´¥æ¬¡æ•°è¿‡å¤šï¼Œç»ˆæ­¢å†å²æ•°æ®è·å–
            if consecutive_failures >= max_consecutive_failures:
                print(f"âŒ å·²è¿ç»­ {consecutive_failures} ä¸ªå¹´ä»½å¤„ç†å¤±è´¥ï¼Œç»ˆæ­¢å†å²æ•°æ®è·å–")
                break
    
    print(f"âœ… å†å²æ•°æ®è·å–å®Œæˆ")
    
    # ç”Ÿæˆå…¨é‡æ•°æ®æŠ¥å‘Š
    cur = db.cursor()
    cur.execute("SELECT * FROM CVE_DB ORDER BY cve DESC;")
    result = cur.fetchall()
    
    # åˆ†ç¦»æœ‰CVEç¼–å·å’Œæ— CVEç¼–å·çš„æ•°æ®
    valid_cve_records = []
    others_records = []
    
    for row in result:
        if row[5].upper() == "CVE NOT FOUND":
            others_records.append(row)
        else:
            valid_cve_records.append(row)
    
    # å†™å…¥æŠ¥å‘Šå¤´éƒ¨
    newline = f"""# å…¨é‡ æƒ…æŠ¥é€Ÿé€’ æ•°æ®æŠ¥å‘Š

> Automatic monitor Github CVE using Github Actions 

## æŠ¥å‘Šä¿¡æ¯
- **ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- **æ•°æ®æ¥æº**: GitHub CVE æ•°æ®åº“
- **æ€»è®°å½•æ•°**: {len(valid_cve_records)}
- **å…¶ä»–è®°å½•æ•°**: {len(others_records)} (è¯¦è§ [others.md](./others.md))

## å…¨é‡æ•°æ®æŠ¥å‘Š

| CVE | ç›¸å…³ä»“åº“ï¼ˆpoc/expï¼‰ | æè¿° | æ—¥æœŸ |
|:---|:---|:---|:---|
"""
    write_file(newline, overwrite=True) # é¦–æ¬¡å†™å…¥æ—¶è¦†ç›–æ–‡ä»¶

    # å†™å…¥æœ‰æ•ˆçš„CVEè®°å½•
    for row in valid_cve_records:
        Publish_Date = row[4]
        Description = row[2].replace('|','-')
        newline = "| [" + row[5].upper() + "](https://www.cve.org/CVERecord?id=" + row[5].upper() + ") | [" + row[1] + "](" + row[3] + ") | " + Description + " | " + Publish_Date + "|\n"
        write_file(newline)
    
    # ç”Ÿæˆothers.mdæŠ¥å‘Š
    if len(others_records) > 0:
        for row in others_records:
            Publish_Date = row[4]
            Description = row[2].replace('|','-')
            newline = "| ğŸš« æœªè¯†åˆ« | [" + row[1] + "](" + row[3] + ") | " + Description + " | " + Publish_Date + "|\n"
            write_others_file(newline)
        
        # æ·»åŠ æŠ¥å‘Šå°¾éƒ¨
        footer = f"\n\n---\n\n**æŠ¥å‘Šç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}  \n**æ€»è®°å½•æ•°**: {len(others_records)}\n"
        write_others_file(footer)
    
    # ç”Ÿæˆå½“æ—¥æŠ¥å‘Š
    
    # è®°å½•åŸå§‹today_listé•¿åº¦
    original_today_list_len = len(today_list)
    print(f"ç”Ÿæˆå½“æ—¥ æƒ…æŠ¥é€Ÿé€’ æŠ¥å‘Šï¼Œå…± {len(today_list)} æ¡è®°å½•")
    
    # å¦‚æœå½“æ—¥æ²¡æœ‰æ•°æ®ï¼Œä½¿ç”¨æœ€è¿‘çš„æ•°æ®
    if len(today_list) == 0:
        print("å½“æ—¥æ— æ•°æ®ï¼Œå°è¯•è·å–æœ€è¿‘7å¤©çš„æ•°æ®...")
        # å…ˆå°è¯•è·å–æœ€è¿‘7å¤©çš„æ•°æ®
        cur = db.cursor()
        # è·å–7å¤©å†…çš„æ•°æ®
        from datetime import timedelta
        seven_days_ago = (today - timedelta(days=7)).strftime("%Y-%m-%d")
        cur.execute(f"SELECT * FROM CVE_DB WHERE created_at >= '{seven_days_ago}' ORDER BY created_at DESC;")
        recent_records = cur.fetchall()
        
        # å¦‚æœ7å¤©å†…æ²¡æœ‰æ•°æ®ï¼Œåˆ™è·å–æœ€è¿‘çš„10æ¡è®°å½•
        if len(recent_records) == 0:
            print("æœ€è¿‘7å¤©æ— æ•°æ®ï¼Œè·å–æœ€è¿‘10æ¡è®°å½•...")
            cur.execute("SELECT * FROM CVE_DB ORDER BY created_at DESC LIMIT 10;")
            recent_records = cur.fetchall()
        
        # è½¬æ¢ä¸ºä¸today_listç›¸åŒçš„æ ¼å¼
        for row in recent_records:
            today_list.append({
                "cve": row[5],
                "full_name": row[1],
                "description": row[2],
                "url": row[3],
                "created_at": row[4]
            })
        
        print(f"å½“æ—¥æ— æ•°æ®ï¼Œä½¿ç”¨æœ€è¿‘ {len(today_list)} æ¡è®°å½•")
    
    # å†™å…¥æ¯æ—¥æŠ¥å‘Šæ–‡ä»¶
    if len(today_list) > 0:
        print(f"æˆåŠŸå†™å…¥ {len(today_list)} æ¡è®°å½•åˆ°æ¯æ—¥ æƒ…æŠ¥é€Ÿé€’ æŠ¥å‘Š")

    # å†™å…¥æ¯æ—¥æŠ¥å‘Šï¼ˆè¿‡æ»¤æ‰CVE NOT FOUNDçš„è®°å½•ï¼‰
    valid_today_list = [entry for entry in today_list if entry["cve"].upper() != "CVE NOT FOUND"]
    
    for entry in valid_today_list:
        cve = entry["cve"]
        full_name = entry["full_name"]
        description = entry["description"].replace('|','-')
        url = entry["url"]
        created_at = entry["created_at"]

        newline = f"| [{cve.upper()}](https://www.cve.org/CVERecord?id={cve.upper()}) | [{full_name}]({url}) | {description} | {created_at}|\n"

        # å†™å…¥æ¯æ—¥æŠ¥å‘Šæ–‡ä»¶
        write_daily_file(daily_file_path, newline)

    # å¦‚æœæ˜¯ä½¿ç”¨æœ€è¿‘è®°å½•ï¼Œåˆ™åœ¨æŠ¥å‘Šä¸­å¢åŠ è¯´æ˜ (ç§»åŠ¨åˆ°æ­¤å¤„)
    if original_today_list_len == 0:
        with open(daily_file_path, 'a', encoding='utf-8') as f:
            f.write("\n\n> ç”±äºæ²¡æœ‰è·å–åˆ°å½“æ—¥æ•°æ®ï¼Œä½¿ç”¨è¿‘7å¤©è®°å½•\n\n")

    # æ›´æ–°ç´¢å¼•æ–‡ä»¶ï¼Œåˆ—å‡ºæ‰€æœ‰æ¯æ—¥æŠ¥å‘Š
    update_daily_index()

    # Statistics
    print("\nğŸ“Š ç”Ÿæˆç»Ÿè®¡æ•°æ®...")
    try:
        import sys
        # è·å–è„šæœ¬æ‰€åœ¨ç›®å½•çš„ç»å¯¹è·¯å¾„
        script_dir = os.path.dirname(os.path.abspath(__file__))
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨ - ä½¿ç”¨å°å†™çš„dataç›®å½•
        daily_dir = os.path.join(PROJECT_ROOT, 'docs', 'data', 'daily')
        stats_dir = os.path.join(PROJECT_ROOT, 'docs', 'data', 'statistics')
        os.makedirs(daily_dir, exist_ok=True)
        os.makedirs(stats_dir, exist_ok=True)
        
        # å…ˆè¿è¡Œæ•°æ®ç”Ÿæˆè„šæœ¬åˆ›å»ºæ±‡æ€»æ–‡ä»¶
        import subprocess
        print("ğŸ“Š æ­£åœ¨ç”Ÿæˆæ±‡æ€»æ•°æ®...")
        
        # æ„å»ºå‘½ä»¤å‚æ•°
        script_path = os.path.join(PROJECT_ROOT, 'scripts/enhanced_daily_data_generator.py')
        
        # å°è¯•ä½¿ç”¨ä¸åŒçš„Pythonè§£é‡Šå™¨è·¯å¾„
        python_executables = [sys.executable, 'python', 'python3']
        success = False
        
        for python_exe in python_executables:
            try:
                print(f"DEBUG: å°è¯•ä½¿ç”¨Pythonè§£é‡Šå™¨: {python_exe}")
                # ä½¿ç”¨shell=Trueåœ¨Windowsä¸Šæ›´å¯é ï¼Œç‰¹åˆ«æ˜¯å½“è·¯å¾„åŒ…å«ç©ºæ ¼æ—¶
                subprocess.run([python_exe, script_path, '--fill-gaps'],
                             check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=(os.name == 'nt'))
                success = True
                print("âœ… æ•°æ®æ±‡æ€»æ–‡ä»¶å·²ç”Ÿæˆ")
                break
            except Exception as e:
                print(f"DEBUG: ä½¿ç”¨ {python_exe} å¤±è´¥: {e}")
                # å¦‚æœä¸æ˜¯æœ€åä¸€ä¸ªå°è¯•ï¼Œç»§ç»­å°è¯•ä¸‹ä¸€ä¸ª
                if python_exe != python_executables[-1]:
                    print(f"DEBUG: å°è¯•ä½¿ç”¨ä¸‹ä¸€ä¸ªPythonè§£é‡Šå™¨...")
                    continue
                else:
                    raise
        
        # å†è¿è¡Œç»Ÿè®¡ç”Ÿæˆè„šæœ¬
        print("ğŸ“ˆ æ­£åœ¨ç”ŸæˆWikiç»Ÿè®¡æ•°æ®...")
        stats_script_path = os.path.join(PROJECT_ROOT, 'scripts/generate_wiki_stats.py')
        
        for python_exe in python_executables:
            try:
                print(f"DEBUG: å°è¯•ä½¿ç”¨Pythonè§£é‡Šå™¨: {python_exe}")
                subprocess.run([python_exe, stats_script_path],
                             check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=(os.name == 'nt'))
                print("âœ… Wikiç»Ÿè®¡æ•°æ®å·²ç”Ÿæˆ")
                break
            except Exception as e:
                print(f"DEBUG: ä½¿ç”¨ {python_exe} å¤±è´¥: {e}")
                if python_exe != python_executables[-1]:
                    print(f"DEBUG: å°è¯•ä½¿ç”¨ä¸‹ä¸€ä¸ªPythonè§£é‡Šå™¨...")
                    continue
                else:
                    raise
    except Exception as e:
        print(f"âš ï¸  ç»Ÿè®¡æ•°æ®ç”Ÿæˆè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        # ç»§ç»­æ‰§è¡Œï¼Œä¸ä¸­æ–­ä¸»æµç¨‹

if __name__ == "__main__":
    # init_file() # ç§»é™¤æ­¤è¡Œï¼Œå› ä¸ºå…¨é‡æŠ¥å‘Šçš„å†™å…¥ä¼šè¦†ç›–æ–‡ä»¶
    main()
